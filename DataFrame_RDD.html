<!DOCTYPE HTML>
<!-- Strata by HTML5 UP html5up.net | @ajlkn Free for personal and commercial use under the CCA 3.0 license (html5up.net/license) -->
<html>

<head>
    <title>奇怪 | Odd-Blog</title>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"/>
    <link rel="stylesheet" href="assets/css/main.css"/>
</head>

<body class="is-preload">
<!-- Header -->
<header id="header">
    <div class="inner">
        <a href="./index.html" class="image avatar" target="_parent">
            <img src="images/avatar.jpg" alt=""/></a>
        <h1>
            <strong>I am HuangQiYong</strong>
            <br/>
            <br/>
        </h1>
    </div>
    <style>
        p {
            font-size: 18px
        }
    </style>
</header>
<!-- Main -->
<div id="main">
    <!-- One -->
    <section id="One">
        <h2>Spark中RDD转DataFrame</h2>
        <section>
            <pre>
spark3.0版本可能不太公布底层的RDD，以后使用dataframe将成为趋势，现在大都数公司也多使用dataframe来处理数据,下面对比下RDD和Dataframe的优缺点。
RDD的优点：
    1.相比于传统的MapReduce框架，Spark在RDD中内置很多函数操作，group，map，filter等，方便处理结构化或非结构化数据。
    2.面向对象编程，直接存储的java对象，类型转化也安全
RDD的缺点：
    1.由于它基本和hadoop一样万能的，因此没有针对特殊场景的优化，比如对于结构化数据处理相对于sql来比非常麻烦
    2.默认采用的是java序列号方式，序列化结果比较大，而且数据存储在java堆内存中，导致gc比较频繁
DataFrame的优点：
    1.结构化数据处理非常方便，支持Avro, CSV, elastic search, and Cassandra等kv数据，也支持HIVE tables, MySQL等传统数据表
    2.有针对性的优化，如采用Kryo序列化，由于数据结构元信息spark已经保存，序列化时不需要带上元信息，大大的减少了序列化大小，而且数据保存在堆外内存中，减少了gc次数,所以运行更快。
    3.hive兼容，支持hql、udf等
DataFrame的缺点：
    1.编译时不能类型转化安全检查，运行时才能确定是否有问题
    2.对于对象支持不友好，rdd内部数据直接以java对象存储，dataframe内存存储的是row对象而不能是自定义对象
测试数据 people.txt
用户ID,年龄
338215,24
686087,8
810117,14
960838,5
594476,11
894998,20

SQLContext在spark2.0之后使用sparksession替代，不过仍然保留了SQLContext。
所以注释掉，改用SparkSession.builder()
<code>import org.apache.spark.sql.SparkSession
import org.apache.spark.SparkConf

object Rdd_Dataframe {
  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setAppName("schametest").setMaster("local[*]")
    //    val contxt  = new SparkContext(conf)
    //    val sc = new SQLContext(contxt)
    val spark = SparkSession.builder().config(conf).getOrCreate()
    val ppRdd = spark.sparkContext.textFile("E:\\people.txt").map(
      line => People(
        line.split(",")(0), line.split(",")(4).trim.toInt
      )
    )
    import spark.implicits._
    val df_table = ppRdd.toDF().createOrReplaceTempView("people")
    val df2 = spark.sql("select * from people where age > 15").show(50)
    spark.stop()
  }
}</code>
运行结果：
+------+---+
|  name|age|
+------+---+
|338215| 24|
|894998| 20|
|548335| 30|
+------+---+


</pre>
        </section>


        <section>

        </section>
    </section>
</div>
<!-- Footer -->
<footer id="footer">
    <div class="inner">
        <ul class="icons">
            <li>
                <a href="https://twitter.com/home" class="icon brands fa-twitter">
                    <span class="label">Twitter</span></a>
            </li>
            <li>
                <a href="https://github.com/Odd-qiguai" class="icon brands fa-github">
                    <span class="label">Github</span></a>
            </li>
            <li>
                <div class="icon solid fa-envelope">
                    <span class="label">Email</span></div>
            </li>
        </ul>
        <ul class="copyright">
            <li>Design:294545122@qq.com</li>
        </ul>
    </div>
</footer>
<!-- Scripts -->
<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.poptrox.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>
<script type="text/javascript" language="javascript">function over() {
    document.getElementById("contain").style.innerHTML = "2";
}

function out() {
    document.getElementById("contain").style.innerHTML = "1";
}</script>
</body>

</html>